{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspired/based on https://github.com/rayidghani/magicloops and https://github.com/dssg/MLforPublicPolicy/blob/master/labs/2019/lab6_feature_generation_sol.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pipeline_evictions as pipeline\n",
    "import ml_loop_evictions as loop\n",
    "\n",
    "import importlib\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "datafile = \"data/tracts.csv\"\n",
    "\n",
    "#Read data, parsing year column to date type\n",
    "data = pd.read_csv(datafile, parse_dates=['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create outcome label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eviction_rate(df, year,geoid):\n",
    "  \n",
    "  data_to_return = df.loc[(df['year'] == year) & (df['GEOID'] == geoid)]\n",
    "  \n",
    "  return data_to_return['eviction-rate'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "#Obtain eviction-rate cutoff for the top 10%, for each year\n",
    "cutoff_10_percent={}\n",
    "for year in range(2000,2017):\n",
    "    year = pd.Timestamp(year,1,1)\n",
    "    cutoff_10_percent[year]=data.loc[data['year'] == year]['eviction-rate'].quantile(.9)\n",
    "    \n",
    "top_10_eviction_rate_in_any_next_3_years_column = np.zeros(len(data))\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "  \n",
    "  #Because the outcome will come from eviction-rate in next 3 years and we have data till 2016,\n",
    "  #features data bust be from 2013 or before\n",
    "  \n",
    "  if(row['year']<=pd.Timestamp(2013,1,1)):    \n",
    "    \n",
    "    found_year_where_eviction_was_in_top_10_percent=0\n",
    "    \n",
    "    #Get eviction for the next 3 years\n",
    "    for i in range(1,4):\n",
    "      date_in_i_years = row['year'] + relativedelta(years=i)\n",
    "      eviction_rate_in_i_years = get_eviction_rate(data, date_in_i_years,row['GEOID'])\n",
    "    \n",
    "      top_10_eviction_rate_in_i_years = 1 if eviction_rate_in_i_years>= cutoff_10_percent[date_in_i_years] else 0\n",
    "      \n",
    "      #Debugging\n",
    "#       if(top_10_eviction_rate_in_i_years==1):\n",
    "#         print(row['GEOID'])\n",
    "#         print(row['year'])\n",
    "#         print(date_in_i_years)\n",
    "#         print(eviction_rate_in_i_years)\n",
    "#         print(cutoff_10_percent[date_in_i_years])\n",
    "#         print(top_10_eviction_rate_in_i_years)        \n",
    "    \n",
    "      #If we found one year that meets requirement, we are done with looping\n",
    "      if(top_10_eviction_rate_in_i_years==1):\n",
    "        found_year_where_eviction_was_in_top_10_percent=1\n",
    "        break\n",
    "\n",
    "    if (found_year_where_eviction_was_in_top_10_percent):\n",
    "      top_10_eviction_rate_in_any_next_3_years_column[index]=1\n",
    "    else:\n",
    "      top_10_eviction_rate_in_any_next_3_years_column[index]=0\n",
    "\n",
    "data['top_10_percent_in_any_next_3_years'] = top_10_eviction_rate_in_any_next_3_years_column\n",
    "\n",
    "label ='top_10_percent_in_any_next_3_years'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create temporal train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Create sets of train and test data, based on different split thresholds\n",
    "#The split thresholds corresponds to the starting date of the testing data\n",
    "\n",
    "#Splits according to https://docs.google.com/spreadsheets/d/1ipqsgThz7hdXXyyNpTuqa4J1inc088lop7lhFsAQ_r0/edit#gid=0\n",
    "split_thresholds = [pd.Timestamp(i,1,1) for i in range (2004, 2014)]\n",
    "\n",
    "#Indicating which is the column to be used for splitting training and test daata\n",
    "date_column='year'\n",
    "\n",
    "#Amount of data used for test set\n",
    "test_window = relativedelta(years=4)\n",
    "\n",
    "#Gap needed between training and test set\n",
    "gap_training_test = relativedelta(years=3)\n",
    "\n",
    "#Generate train and test sets\n",
    "train_test_sets= pipeline.create_temp_validation_train_and_testing_sets(\n",
    "  data,\n",
    "  date_column,\n",
    "  label,\n",
    "  split_thresholds,\n",
    "  test_window,\n",
    "  gap_training_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Impute data on continuous columns for each training and test set\n",
    "\n",
    "#--->PENDING\n",
    "#In the meantime, imputing all float columns with mean\n",
    "\n",
    "float_columns = [column for column in data.columns if data[column].dtype=='float']\n",
    "\n",
    "#Do not consider GEOID column\n",
    "float_columns=float_columns[1:]\n",
    "\n",
    "for train_test_set in train_test_sets:\n",
    "  train_data = train_test_set['x_train']\n",
    "  test_data = train_test_set['x_test']\n",
    "\n",
    "  #fill na values with mean\n",
    "  pipeline.fill_na_columns_with_mean(train_data, float_columns)\n",
    "  pipeline.fill_na_columns_with_mean(test_data, float_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_generation as fg\n",
    "\n",
    "importlib.reload(pipeline)\n",
    "importlib.reload(fg)\n",
    "\n",
    "#We will have to generate features independently for each different train/test set\n",
    "for train_test_set in train_test_sets:\n",
    "\n",
    "#   train_features, test_features = pipeline.create_features(train_test_set)\n",
    "  \n",
    "  #NEW VERSION\n",
    "  train_features = fg.create_features(train_test_set['x_train'])\n",
    "  test_features = fg.create_features(train_test_set['x_test']) \n",
    "\n",
    "  \n",
    "  #print(train_features)\n",
    "  \n",
    "  #Replace raw data in train_test_set with features generated\n",
    "  train_test_set['x_train'] = train_features\n",
    "  train_test_set['x_test'] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feature_generation as fg\n",
    "\n",
    "importlib.reload(pipeline)\n",
    "importlib.reload(fg)\n",
    "\n",
    "a = train_test_sets[len(train_test_sets)-1]['x_train']\n",
    "\n",
    "a.to_csv(\"hi.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in a.columns:\n",
    "  if(a[column].isnull().values.any()):\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    " #OLD VERSION: \n",
    "#   \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "#train_test_sets\n",
    "# len(train_test_sets[0]['x_train'].columns)\n",
    "\n",
    "# for column in train_test_sets[0]['x_train'].columns:\n",
    "#   print(column)\n",
    "\n",
    "# # train_test_sets[0]['x_train'].drop(columns=['GEOID', 'name'], inplace=True)\n",
    "  \n",
    "# train_test_sets[0]['x_train']\n",
    "# train_test_sets[0]['x_test'].head()\n",
    "\n",
    "# for column in train_test_sets[0]['x_test'].columns:\n",
    "#   print(column)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Clasifiers and parameters generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#We define the specific models we want to run\n",
    "models_to_run=['DT','LR','RF','ET','KNN','NB','BA','AB','GB']#'SVM'\n",
    "\n",
    "#Get all posible models and their different sets of parameters\n",
    "models, parameters_grid = pipeline.get_models_and_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop over models and different training/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-06 23:56:54.870567: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:55.116467: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:55.355735: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:55.598672: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:55.860621: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:56.103249: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:56.343158: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:56.581095: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:56.856421: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:57.166400: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:57.404709: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:57.647394: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:57.908797: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:58.159671: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:58.423251: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:58.676763: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:58.938041: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:59.183419: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:59.428567: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:59.668788: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:56:59.940502: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:00.317877: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:00.683539: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:01.464183: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:01.835727: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:02.683276: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:03.072655: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:20.025135: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:20.392602: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:20.944187: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:21.417253: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:21.912227: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:22.589567: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:23.087140: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:23.582348: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:24.028678: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:24.522414: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:24.986242: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:25.494007: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:26.009713: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:26.719606: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:27.212051: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:27.704269: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:28.216709: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:28.868156: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:29.373526: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:30.943889: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:31.429878: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:33.326811: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:33.834665: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:35.296999: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:35.783746: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-06 23:57:37.254356: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:37.701850: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:39.003032: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:39.487438: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:41.413598: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:41.699603: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:42.150396: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:42.444228: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:42.742368: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:43.057391: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:43.372178: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:43.742743: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:44.138268: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:44.538993: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:44.974949: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:45.406004: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:45.849023: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:46.285007: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:46.724759: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:47.180353: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:47.627967: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:48.133516: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:48.628863: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:49.181029: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:49.753394: Running NB with params: {} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:49.998266: Running BA with params: {'max_features': 1, 'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:50.353228: Running BA with params: {'max_features': 1, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:51.910008: Running BA with params: {'max_features': 10, 'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:52.255634: Running BA with params: {'max_features': 10, 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:53.493696: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:53.739097: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:54.167303: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:54.405241: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:54.641854: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:54.910695: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:55.165063: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:55.506750: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:55.892983: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:56.140504: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:56.392151: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:56.719101: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2004-01-01 00:00:00\n",
      "2019-06-06 23:57:57.072566: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:57.334466: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:57.569163: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:57.835191: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:58.092389: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:58.371746: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:58.654760: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:58.949836: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:59.244426: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:59.529282: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:57:59.819491: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:00.065978: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:00.326145: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:00.588608: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-06 23:58:00.869563: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:01.163797: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:01.454425: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:01.743415: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:02.044799: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:02.343520: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:02.632590: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:03.144556: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:03.733062: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:06.140709: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:06.585530: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:12.150782: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:12.509135: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:18.400247: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:18.775492: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:19.320814: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:19.960501: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:20.432249: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:21.107488: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:21.592550: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:22.058039: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:22.492924: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:22.960563: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:23.405029: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:24.060869: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:24.496161: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:25.119461: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:25.600839: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:26.222991: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:26.690872: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:27.337870: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:27.846580: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:29.469460: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:29.960362: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:31.822214: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:32.388617: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:34.804782: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:35.311771: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:37.289469: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:37.781641: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:39.337674: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:39.952163: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:42.337637: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:42.681945: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:43.332589: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:43.674773: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:44.048165: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:44.407862: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:44.742398: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:45.153355: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:45.568565: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:46.032003: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-06 23:58:46.499510: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:46.940516: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:47.383914: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:47.829295: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:48.290447: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:48.721508: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:49.161300: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:49.664365: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:50.175364: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:50.713906: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:51.269077: Running NB with params: {} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:51.502130: Running BA with params: {'max_features': 1, 'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:51.980009: Running BA with params: {'max_features': 1, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:55.062714: Running BA with params: {'max_features': 10, 'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:55.417281: Running BA with params: {'max_features': 10, 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:57.268616: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:57.602288: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:58.812026: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:58:59.161961: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:00.430069: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:00.726671: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:01.057485: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:01.761087: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:02.809048: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:03.091013: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:03.420084: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:04.124819: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2005-01-01 00:00:00\n",
      "2019-06-06 23:59:05.164130: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:05.420219: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:05.674444: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:05.977062: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:06.270015: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:06.592263: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:06.925626: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:07.258526: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:07.588425: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:07.939787: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:08.282477: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:08.546700: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:09.203357: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:09.491755: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:09.769396: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:10.086892: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:10.401495: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:10.723530: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:11.049034: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:11.372604: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:11.692199: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:12.422773: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:13.389265: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:17.092033: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:18.150870: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:26.646192: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:28.197920: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:38.334669: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:39.257786: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:39.771439: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-06 23:59:40.504957: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:40.955914: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:41.696192: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:42.164942: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:42.900926: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:43.346568: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:43.960277: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:44.436540: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:45.102772: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:45.585427: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:46.304389: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:46.747764: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:47.494676: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:47.952502: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:48.914589: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:49.392491: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:51.202269: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:51.698766: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:53.304419: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:53.946996: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:56.740512: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:57.212983: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:59.120827: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-06 23:59:59.620815: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:01.302230: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:02.065825: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:05.741220: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:06.065330: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:06.382782: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:06.712933: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:07.052296: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:07.401099: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:07.764806: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:08.220416: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:08.667477: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:09.186570: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:09.719543: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:10.189474: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:11.146224: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:11.588740: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:12.042418: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:12.505746: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:12.995560: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:13.575489: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:14.177679: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:14.823527: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:15.472792: Running NB with params: {} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:15.728292: Running BA with params: {'max_features': 1, 'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:16.327151: Running BA with params: {'max_features': 1, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:21.208456: Running BA with params: {'max_features': 10, 'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:21.622005: Running BA with params: {'max_features': 10, 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 00:00:23.778512: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:24.129347: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:25.569421: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:25.947042: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:27.489206: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:27.835390: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:28.217315: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:29.247249: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:30.730350: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:31.076005: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:31.452735: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:32.459505: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2006-01-01 00:00:00\n",
      "2019-06-07 00:00:33.943511: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:34.216794: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:34.489767: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:34.802501: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:35.108228: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:35.450985: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:35.808565: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:36.177430: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:36.536906: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:36.907762: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:37.275686: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:37.552849: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:37.834918: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:38.160387: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:38.480085: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:38.862671: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:39.237588: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:39.617948: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:40.013040: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:40.404031: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:40.794873: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:41.535645: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:42.558715: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:47.275699: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:48.067081: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:57.816192: Running LR with params: {'C': 1, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:00:59.087548: Running LR with params: {'C': 10, 'penalty': 'l1'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:12.730846: Running LR with params: {'C': 10, 'penalty': 'l2'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:14.409266: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:15.664527: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:17.015455: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:18.006949: Running RF with params: {'max_depth': 5, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:19.068102: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:19.539205: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:20.171942: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:20.622365: Running RF with params: {'max_depth': 5, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:21.229540: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:21.824653: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:22.799249: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:23.258416: Running RF with params: {'max_depth': 50, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:24.224126: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 00:01:24.669165: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 2, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:25.741841: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 10, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:26.463695: Running RF with params: {'max_depth': 50, 'max_features': 'log2', 'min_samples_split': 10, 'n_estimators': 100, 'n_jobs': -1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:27.400120: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:27.968731: Running ET with params: {'criterion': 'gini', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:30.758134: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:31.643868: Running ET with params: {'criterion': 'gini', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:34.445481: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:35.138192: Running ET with params: {'criterion': 'gini', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:39.446896: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:40.125730: Running ET with params: {'criterion': 'entropy', 'max_depth': 2, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:42.278709: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:43.091970: Running ET with params: {'criterion': 'entropy', 'max_depth': 5, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:45.497069: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:46.583919: Running ET with params: {'criterion': 'entropy', 'max_depth': 50, 'n_estimators': 1000} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:51.329350: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:51.748169: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:52.164672: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:52.628198: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:53.135867: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:53.722256: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:54.200089: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:54.743119: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:55.308757: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:55.935250: Running KNN with params: {'algorithm': 'auto', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:56.814559: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:57.633836: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 3, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:58.527211: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:01:59.473868: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 5, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:00.436103: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:01.422981: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 10, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:02.823484: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:05.567112: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 50, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:07.182134: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'uniform'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:09.249824: Running KNN with params: {'algorithm': 'ball_tree', 'n_neighbors': 100, 'weights': 'distance'} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:10.673413: Running NB with params: {} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:10.936209: Running BA with params: {'max_features': 1, 'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:11.999925: Running BA with params: {'max_features': 1, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:21.277160: Running BA with params: {'max_features': 10, 'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:22.278744: Running BA with params: {'max_features': 10, 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:27.741920: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:28.834886: Running AB with params: {'algorithm': 'SAMME', 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:32.836302: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 10} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:33.398191: Running AB with params: {'algorithm': 'SAMME.R', 'n_estimators': 100} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:35.286774: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:35.654556: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:36.079778: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:37.297215: Running GB with params: {'learning_rate': 0.001, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:39.257297: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:39.654659: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 10, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:40.123985: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 0.1} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:41.391326: Running GB with params: {'learning_rate': 0.1, 'n_estimators': 100, 'subsample': 1.0} on train/test set 2007-01-01 00:00:00\n",
      "2019-06-07 00:02:43.317088: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:43.640049: Running DT with params: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-07 00:02:43.963969: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:44.300145: Running DT with params: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:44.621423: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:45.012508: Running DT with params: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:45.376318: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:45.762386: Running DT with params: {'criterion': 'gini', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:46.168461: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:46.557454: Running DT with params: {'criterion': 'gini', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:46.959252: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:47.250612: Running DT with params: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:47.536822: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:48.057280: Running DT with params: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:49.504938: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:50.556701: Running DT with params: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:52.037087: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:53.095587: Running DT with params: {'criterion': 'entropy', 'max_depth': 50, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:53.850642: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 2} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:54.648021: Running DT with params: {'criterion': 'entropy', 'max_depth': 100, 'min_samples_split': 5} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:55.271732: Running LR with params: {'C': 0.001, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:56.623183: Running LR with params: {'C': 0.001, 'penalty': 'l2'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:02:58.327948: Running LR with params: {'C': 0.1, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:03:05.404538: Running LR with params: {'C': 0.1, 'penalty': 'l2'} on train/test set 2008-01-01 00:00:00\n",
      "2019-06-07 00:03:07.449239: Running LR with params: {'C': 1, 'penalty': 'l1'} on train/test set 2008-01-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(pipeline)\n",
    "importlib.reload(loop)\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "results = loop.iterate_over_models_and_training_test_sets(models_to_run, models, parameters_grid, train_test_sets)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observe best models for each train/test set, for different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "#Lets obtain the best model for each train/test set, for each metric\n",
    "metrics_to_display = ['p_at_5','p_at_10', 'auc-roc']\n",
    "\n",
    "best_models_per_metric = {}\n",
    "\n",
    "for metric in metrics_to_display:\n",
    "    #indices of rows that have max value in specific metric for each train/test set\n",
    "    idx = results.groupby(['test_set_start_date'])[metric].transform(max) == results[metric]\n",
    "\n",
    "    #save table of best models at the specific metric\n",
    "    best_models_per_metric[metric] = results[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models for Precision at 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models_per_metric['p_at_5'].iloc[:, [0,2,3,4,11,12,13]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models for Precision at 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_models_per_metric['p_at_10'].iloc[:, [0,2,3,4,14,15,16]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best models for AUC-ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_per_metric['auc-roc'].iloc[:, [0,2,3,4,26]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot of all model types performance at different train/test sets, for the different metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pipeline)\n",
    "\n",
    "for metric in metrics_to_display:\n",
    "    #For each model, find the set of parameters that work the best in each train/test set\n",
    "    best_models = pipeline.get_best_models_of_each_type_for_each_train_test_set(models_to_run,results,'test_set_start_date', metric)\n",
    "    pipeline.plot_models_in_time(models_to_run, best_models, metric)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
